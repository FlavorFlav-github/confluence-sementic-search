from abc import abstractmethod, ABC
from typing import Any, Dict


class LLMAdapter(ABC):
    """
    Abstract Base Class (ABC) for any Large Language Model (LLM) backend.

    This class defines the interface for different LLM implementations
    (e.g., using Ollama, Hugging Face Transformers, OpenAI API, etc.)
    to ensure a consistent way of interacting with them within the application.
    It inherits from `ABC` to enforce implementation of abstract methods.
    """

    def __init__(self, search_system: Any, model_name: str):
        """
        Initializes the LLMAdapter with a search system and model name.

        Args:
            search_system (Any): An object representing the retrieval/search system (e.g., a vector database client)
                                 used for Retrieval-Augmented Generation (RAG).
            model_name (str): The specific name or identifier of the LLM to be used.
        """
        self.search = search_system  # Stores the search/retrieval system instance
        self.model_name = model_name  # Stores the name of the LLM
        self.is_ready = False
        # Default system prompt for instructing the LLM, particularly for RAG
        self.system_prompt = """You are a helpful AI assistant that answers questions based on provided documentation.
        INSTRUCTIONS:
        - Answer based ONLY on the provided context
        - Be concise but comprehensive
        - If you don't exactly know what an acronym stands for, don't try to guess it is probably a product name or an internal service
        - If information is missing, say so clearly
        - Use bullet points or numbered lists when appropriate
        - Use markdown table if necessary
        - Use markdown code snippet if necessary"""

    @abstractmethod
    def setup(self) -> bool:
        """
        Abstract method to set up the LLM backend.

        This can involve installing dependencies, loading the model into memory,
        initializing connections, or performing other necessary setup steps.

        Returns:
            bool: True if setup was successful, False otherwise.
        """
        pass

    @abstractmethod
    def ask(self, question: str, max_token: int = 500, temp: float = 0.2) -> Dict:
        """
        Abstract method to ask a question, perform RAG, and get an answer.

        This method typically involves:
        1. Using the `self.search` system to retrieve relevant context documents based on the `question`.
        2. Constructing a final prompt by combining the `self.system_prompt`, retrieved context, and the `question`.
        3. Calling the internal `_generate` method to get the LLM's response.

        Args:
            question (str): The user's question to be answered.

        Returns:
            Dict: A dictionary containing the answer and potentially other metadata (e.g., retrieved sources).
        """
        pass

    @abstractmethod
    def _generate(self, prompt: str) -> str:
        """
        Abstract core method to interact directly with the specific LLM backend.

        This method handles the low-level details of sending the prompt to the LLM
        (via API call, local model inference, etc.) and receiving the raw response.

        Args:
            prompt (str): The full, constructed prompt (including context and instructions) to send to the LLM.

        Returns:
            str: The raw text response generated by the LLM.
        """
        pass
